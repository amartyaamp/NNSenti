{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "##### Output -\n",
    "Model for predicting sentiment class\n",
    "##### Notes -\n",
    "I am using a feed forward 1 hidden layer net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "# print data[:,0]\n",
    "# print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations = 50,\\\n",
    "                 learning_rate = 0.02):\n",
    "        \n",
    "        self.input = input + 1 # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # set up array of 1s for activations\n",
    "        self.ai = [1.0] * self.input\n",
    "        self.ah = [1.0] * self.hidden\n",
    "        self.ao = [1.0] * self.output\n",
    "        # create randomized weights\n",
    "        self.wi = np.random.randn(self.input, self.hidden) \n",
    "        self.wo = np.random.randn(self.hidden, self.output) \n",
    "        # create arrays of 0 for changes\n",
    "        #self.ci = np.zeros((self.input, self.hidden))\n",
    "        #self.co = np.zeros((self.hidden, self.output))\n",
    "\n",
    "        \n",
    "    def feedForward(self, inputs):\n",
    "       \n",
    "        assert(len(inputs) == self.input-1)\n",
    "        \n",
    "        # input activations\n",
    "        for i in range(self.input -1): # -1 is to avoid the bias\n",
    "            self.ai[i] = inputs[i]\n",
    "        # hidden activations\n",
    "        for j in range(self.hidden):\n",
    "            sum = 0.0\n",
    "            for i in range(self.input):\n",
    "                sum += self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "        # output activations\n",
    "        for k in range(self.output):\n",
    "            sum = 0.0\n",
    "            for j in range(self.hidden):\n",
    "                sum += self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "        return self.ao[:]\n",
    "    \n",
    "    \n",
    "    def backPropagate(self, targets, N):\n",
    "        \n",
    "        assert(len(targets) == self.output)\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        # the delta tell you which direction to change the weights\n",
    "        output_deltas = [0.0] * self.output\n",
    "        for k in range(self.output):\n",
    "            error = -(targets[k] - self.ao[k])\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "        \n",
    "        # calculate error terms for hidden\n",
    "        # delta tells you which direction to change the weights\n",
    "        hidden_deltas =  [0.0] * self.hidden\n",
    "        for j in range(self.hidden):\n",
    "            error = 0.0\n",
    "            for k in range(self.output):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "        \n",
    "        # update the weights hidden-output\n",
    "        for j in range(self.hidden):\n",
    "            for k in range(self.output):\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] -= N * change #+ self.co[j][k]\n",
    "                #self.co[j][k] = change\n",
    "        \n",
    "        # update the weights input-hidden\n",
    "        for i in range(self.input):\n",
    "            for j in range(self.hidden):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                self.wi[i][j] -= N * change #+ self.ci[i][j]\n",
    "                #self.ci[i][j] = change\n",
    "        \n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error += 0.5 * (targets[k] - self.ao[k]) ** 2\n",
    "        return error\n",
    "    \n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        # N: learning rate\n",
    "        itercount = 0\n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            error, prev_error = 0.0, 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[1:]\n",
    "                targets = p[0]\n",
    "                self.feedForward(inputs)\n",
    "                error = self.backPropagate([targets],\\\n",
    "                                           self.learning_rate)\n",
    "                        \n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for p in patterns:\n",
    "            pred = self.feedForward(p[1:])\n",
    "            res = 1 if pred[0] >= 0.5 else 0\n",
    "            if logs:\n",
    "                print \"{} -> {}\".format(p[0], res)\n",
    "            if p[0] == res:\n",
    "                if p[0] == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if p[0] == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        precision =  float(tp)/float(tp+fp)\n",
    "        recall = float(tp)/float(tp+fn)\n",
    "        fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        if logs:\n",
    "            print \"precision - {}\".format(precision)\n",
    "            print \"recall - {}\".format(recall)\n",
    "            print \"F1 score - {}\".format(fscore)\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, False)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "\n",
    "X_test = X[:int(0.2*ninputs)]\n",
    "X_train = X[int(0.2*ninputs):]\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "#test_NN(nfeatures, X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training iteration- 50\n",
      "Begin training!!\n",
      "error 0.37151\n",
      "error 0.04308\n",
      "error 0.03913\n",
      "error 0.03786\n",
      "error 0.03588\n",
      "Total iterations- 50\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -50\n",
      "Begin training iteration- 100\n",
      "Begin training!!\n",
      "Total iterations- 0\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -100\n",
      "Begin training iteration- 200\n",
      "Begin training!!\n",
      "error 0.01497\n",
      "error 0.01571\n",
      "error 0.01592\n",
      "error 0.01473\n",
      "error 0.01285\n",
      "error 0.01080\n",
      "error 0.00883\n",
      "error 0.00707\n",
      "error 0.00556\n",
      "error 0.00429\n",
      "error 0.00327\n",
      "error 0.00246\n",
      "error 0.00183\n",
      "error 0.00135\n",
      "error 0.00099\n",
      "error 0.00072\n",
      "error 0.00052\n",
      "Total iterations- 170\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -200\n",
      "Begin training iteration- 500\n",
      "Begin training!!\n",
      "error 0.21165\n",
      "error 0.12792\n",
      "error 0.08130\n",
      "error 0.06822\n",
      "error 0.06276\n",
      "error 0.05896\n",
      "error 0.05534\n",
      "error 0.05157\n",
      "error 0.04763\n",
      "error 0.04361\n",
      "error 0.03957\n",
      "error 0.03560\n",
      "error 0.03176\n",
      "error 0.02811\n",
      "error 0.02469\n",
      "error 0.02154\n",
      "error 0.01869\n",
      "error 0.01615\n",
      "error 0.01392\n",
      "error 0.01196\n",
      "error 0.01027\n",
      "error 0.00882\n",
      "error 0.00758\n",
      "error 0.00653\n",
      "error 0.00565\n",
      "error 0.00490\n",
      "error 0.00428\n",
      "error 0.00375\n",
      "error 0.00330\n",
      "error 0.00291\n",
      "error 0.00258\n",
      "error 0.00231\n",
      "error 0.00208\n",
      "error 0.00191\n",
      "error 0.00177\n",
      "error 0.00166\n",
      "error 0.00158\n",
      "error 0.00152\n",
      "error 0.00146\n",
      "error 0.00140\n",
      "error 0.00132\n",
      "error 0.00122\n",
      "error 0.00110\n",
      "error 0.00099\n",
      "error 0.00087\n",
      "error 0.00077\n",
      "error 0.00067\n",
      "error 0.00058\n",
      "error 0.00051\n",
      "Total iterations- 490\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "neurons = [5, 10, 20, 50]\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABj0AAAEXCAYAAAD2l4ZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAKAp/H/ZU7XQQVMsBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb652160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['50', '100', '200', '500'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
