{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "##### Output -\n",
    "Model for predicting sentiment class\n",
    "##### Notes -\n",
    "I am using a feed forward 1 hidden layer net. Using only count vectors as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load the data from the file and create the input matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        \n",
    "        #skip punctuations\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[[ 0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "# Main function to form the input matrix\n",
    "#TODO - maybe form a loader class later\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "print data[:,0]\n",
    "print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN\n",
    "\n",
    "A feed forward net is formed using back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations = 50,\\\n",
    "                 learning_rate = 0.02):\n",
    "        \n",
    "        self.input = input + 1 # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # set up array of 1s for activations\n",
    "        self.ai = [1.0] * self.input\n",
    "        self.ah = [1.0] * self.hidden\n",
    "        self.ao = [1.0] * self.output\n",
    "        # create randomized weights\n",
    "        self.wi = np.random.randn(self.input, self.hidden) \n",
    "        self.wo = np.random.randn(self.hidden, self.output) \n",
    "        # create arrays of 0 for changes\n",
    "        #self.ci = np.zeros((self.input, self.hidden))\n",
    "        #self.co = np.zeros((self.hidden, self.output))\n",
    "\n",
    "        \n",
    "    def feedForward(self, inputs):\n",
    "       \n",
    "        assert(len(inputs) == self.input-1)\n",
    "        \n",
    "        # input activations\n",
    "        for i in range(self.input -1): # -1 is to avoid the bias\n",
    "            self.ai[i] = inputs[i]\n",
    "        # hidden activations\n",
    "        for j in range(self.hidden):\n",
    "            sum = 0.0\n",
    "            for i in range(self.input):\n",
    "                sum += self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "        # output activations\n",
    "        for k in range(self.output):\n",
    "            sum = 0.0\n",
    "            for j in range(self.hidden):\n",
    "                sum += self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "        return self.ao[:]\n",
    "    \n",
    "    \n",
    "    def backPropagate(self, targets, N):\n",
    "        \n",
    "        assert(len(targets) == self.output)\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        # the delta tell you which direction to change the weights\n",
    "        output_deltas = [0.0] * self.output\n",
    "        for k in range(self.output):\n",
    "            error = -(targets[k] - self.ao[k])\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "        \n",
    "        # calculate error terms for hidden\n",
    "        # delta tells you which direction to change the weights\n",
    "        hidden_deltas =  [0.0] * self.hidden\n",
    "        for j in range(self.hidden):\n",
    "            error = 0.0\n",
    "            for k in range(self.output):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "        \n",
    "        # update the weights hidden-output\n",
    "        for j in range(self.hidden):\n",
    "            for k in range(self.output):\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] -= N * change #+ self.co[j][k]\n",
    "                #self.co[j][k] = change\n",
    "        \n",
    "        # update the weights input-hidden\n",
    "        for i in range(self.input):\n",
    "            for j in range(self.hidden):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                self.wi[i][j] -= N * change #+ self.ci[i][j]\n",
    "                #self.ci[i][j] = change\n",
    "        \n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error += 0.5 * (targets[k] - self.ao[k]) ** 2\n",
    "        return error\n",
    "    \n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        # N: learning rate\n",
    "        itercount = 0\n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            error, prev_error = 0.0, 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[1:]\n",
    "                targets = p[0]\n",
    "                self.feedForward(inputs)\n",
    "                error = self.backPropagate([targets],\\\n",
    "                                           self.learning_rate)\n",
    "                        \n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for p in patterns:\n",
    "            pred = self.feedForward(p[1:])\n",
    "            res = 1 if pred[0] >= 0.5 else 0\n",
    "            if logs:\n",
    "                print \"{} -> {}\".format(p[0], res)\n",
    "            if p[0] == res:\n",
    "                if p[0] == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if p[0] == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        precision =  float(tp)/float(tp+fp)\n",
    "        recall = float(tp)/float(tp+fn)\n",
    "        fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        if logs:\n",
    "            print \"precision - {}\".format(precision)\n",
    "            print \"recall - {}\".format(recall)\n",
    "            print \"F1 score - {}\".format(fscore)\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "## test the NN by feeding in the X_train, X_test - output gives a \n",
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, False)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "\n",
    "X_test = X[:int(0.2*ninputs)]\n",
    "X_train = X[int(0.2*ninputs):]\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "#test_NN(nfeatures, X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets change iterations and check the effect on fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training iteration- 50\n",
      "Begin training!!\n",
      "error 0.37151\n",
      "error 0.04308\n",
      "error 0.03913\n",
      "error 0.03786\n",
      "error 0.03588\n",
      "Total iterations- 50\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -50\n",
      "Begin training iteration- 100\n",
      "Begin training!!\n",
      "Total iterations- 0\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -100\n",
      "Begin training iteration- 200\n",
      "Begin training!!\n",
      "error 0.01497\n",
      "error 0.01571\n",
      "error 0.01592\n",
      "error 0.01473\n",
      "error 0.01285\n",
      "error 0.01080\n",
      "error 0.00883\n",
      "error 0.00707\n",
      "error 0.00556\n",
      "error 0.00429\n",
      "error 0.00327\n",
      "error 0.00246\n",
      "error 0.00183\n",
      "error 0.00135\n",
      "error 0.00099\n",
      "error 0.00072\n",
      "error 0.00052\n",
      "Total iterations- 170\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -200\n",
      "Begin training iteration- 500\n",
      "Begin training!!\n",
      "error 0.21165\n",
      "error 0.12792\n",
      "error 0.08130\n",
      "error 0.06822\n",
      "error 0.06276\n",
      "error 0.05896\n",
      "error 0.05534\n",
      "error 0.05157\n",
      "error 0.04763\n",
      "error 0.04361\n",
      "error 0.03957\n",
      "error 0.03560\n",
      "error 0.03176\n",
      "error 0.02811\n",
      "error 0.02469\n",
      "error 0.02154\n",
      "error 0.01869\n",
      "error 0.01615\n",
      "error 0.01392\n",
      "error 0.01196\n",
      "error 0.01027\n",
      "error 0.00882\n",
      "error 0.00758\n",
      "error 0.00653\n",
      "error 0.00565\n",
      "error 0.00490\n",
      "error 0.00428\n",
      "error 0.00375\n",
      "error 0.00330\n",
      "error 0.00291\n",
      "error 0.00258\n",
      "error 0.00231\n",
      "error 0.00208\n",
      "error 0.00191\n",
      "error 0.00177\n",
      "error 0.00166\n",
      "error 0.00158\n",
      "error 0.00152\n",
      "error 0.00146\n",
      "error 0.00140\n",
      "error 0.00132\n",
      "error 0.00122\n",
      "error 0.00110\n",
      "error 0.00099\n",
      "error 0.00087\n",
      "error 0.00077\n",
      "error 0.00067\n",
      "error 0.00058\n",
      "error 0.00051\n",
      "Total iterations- 490\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precisions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f588a444f7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;31m# print precisions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m# print fscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecalls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precisions' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['50', '100', '200', '500'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check whether neuron values affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training neuron- 5\n",
      "Begin training!!\n",
      "error 0.39961\n",
      "error 0.14983\n",
      "error 0.12071\n",
      "error 0.11106\n",
      "error 0.10847\n",
      "error 0.10863\n",
      "error 0.10998\n",
      "error 0.11198\n",
      "error 0.11441\n",
      "error 0.11721\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with neuron -5\n",
      "Begin training neuron- 10\n",
      "Begin training!!\n",
      "error 0.00560\n",
      "error 0.01668\n",
      "error 0.03797\n",
      "error 0.05344\n",
      "error 0.06078\n",
      "error 0.06382\n",
      "error 0.06500\n",
      "error 0.06539\n",
      "error 0.06543\n",
      "error 0.06529\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with neuron -10\n",
      "Begin training neuron- 20\n",
      "Begin training!!\n",
      "error 0.20505\n",
      "error 0.06044\n",
      "error 0.04085\n",
      "error 0.03813\n",
      "error 0.03935\n",
      "error 0.04164\n",
      "error 0.04429\n",
      "error 0.04719\n",
      "error 0.05036\n",
      "error 0.05383\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with neuron -20\n",
      "Begin training neuron- 30\n",
      "Begin training!!\n",
      "error 0.01927\n",
      "error 0.01366\n",
      "error 0.01358\n",
      "error 0.01147\n",
      "error 0.00941\n",
      "error 0.00778\n",
      "error 0.00645\n",
      "error 0.00531\n",
      "error 0.00433\n",
      "error 0.00349\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with neuron -30\n"
     ]
    }
   ],
   "source": [
    "### Now test with different neuron values for iteration limit of 100\n",
    "neurons = [5, 10, 20, 30]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of iterations to be 100\n",
    "for neuron in neurons:\n",
    "    print \"Begin training neuron- {}\".format(neuron)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, 100, neuron, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with neuron -{}\".format(neuron)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x468cc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neurons = [10, 20, 30, 40]\n",
    "neurons = np.asarray(neurons)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(neurons-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(neurons, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(neurons+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(neurons, ['5', '10', '20', '30'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
