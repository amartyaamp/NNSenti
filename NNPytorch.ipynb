{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "#### Output -\n",
    "Model for predicting sentiment class\n",
    "#### Notes -\n",
    "I am using a feed forward 1 hidden layer net. Using only count vectors as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load the data from the file and create the input matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        \n",
    "        #skip punctuations\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[[ 0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "# Main function to form the input matrix\n",
    "#TODO - maybe form a loader class later\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "print data[:,0]\n",
    "print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN\n",
    "\n",
    "A feed forward net is formed using back-propagation. Here we change as to use of torch.nn framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the below sigmoid funcs are not needed keeping them redundantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix as a performance evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, tp=0, tn=0, fp=0, fn=0):\n",
    "        \n",
    "        self.tp = tp\n",
    "        self.tn = tn\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def dispMatrix(self):\n",
    "        \n",
    "        s = \"|{}|{}|\".format(self.tp, self.fn)\n",
    "        s += \"\\n-------\"\n",
    "        s += \"\\n|{}|{}|\".format(self.fp, self.tn)\n",
    "        s += \"\\n-------\"\n",
    "        print s\n",
    "        return s\n",
    "    \n",
    "    def getPrecision(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fp);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    \n",
    "    def getRecall(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fn);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations=50,\\\n",
    "                 learning_rate = 0.02, batchsize=100):\n",
    "        \n",
    "        # all the parameters' count\n",
    "        self.input = input # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batchsize = batchsize\n",
    "        \n",
    "        ## Since it is torch.NN, we need inputs and output \n",
    "        ## tensors instead of weights\n",
    "        self.model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.input, self.hidden),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(self.hidden, self.output),\n",
    "          torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "        \n",
    "        # Metrics for the model\n",
    "        self.cmatrix = ConfusionMatrix()\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.f1 = 0.0\n",
    "        \n",
    "        #the graphics elements\n",
    "        self.vis = visdom.Visdom()\n",
    "        self.win_f1 = None\n",
    "        self.win_err = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        \n",
    "        dtype = torch.FloatTensor\n",
    "        itercount = 0\n",
    "        error, prev_error = 0.0, 0.0\n",
    "        \n",
    "        #type casting required to make all of them float Tensor\n",
    "        targets = Variable(patterns[:,0].type(dtype), requires_grad=False)\n",
    "        inputs = Variable(patterns[:,1:].type(dtype))\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            \n",
    "            ##feed forward\n",
    "            predictions = self.model(inputs)\n",
    "            self.error = self.loss_fn(predictions, targets)\n",
    "            \n",
    "            error = self.error.data[0]\n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            self.error.backward() # do backpropagation now\n",
    "            \n",
    "            for param in self.model.parameters():\n",
    "                param.data -= self.learning_rate * param.grad.data\n",
    "            \n",
    "            #quantize the predictions to 0 or 1\n",
    "            predictions = (predictions >= 0.5).type(dtype)\n",
    "            \n",
    "            ## TODO - uncomment to set the confusion matrix stats\n",
    "            self.updateMetrics(targets, predictions)\n",
    "            \n",
    "            # Get the vizdom plot\n",
    "            self.monitorMetrics(itercount)\n",
    "            \n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    print \"breaking the game\"\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateMetrics(self, targets, predictions):\n",
    "        \n",
    "        for i,_ in enumerate(predictions):\n",
    "            if predictions[i].data[0] == targets[i].data[0]:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    self.cmatrix.tp += 1\n",
    "                else:\n",
    "                    self.cmatrix.tn += 1\n",
    "            else:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    self.cmatrix.fn += 1\n",
    "                else:\n",
    "                    self.cmatrix.fp += 1\n",
    "        \n",
    "        self.precision = self.cmatrix.getPrecision()\n",
    "#         print \"Precision-{}\".format(self.precision)\n",
    "        self.recall = self.cmatrix.getRecall()\n",
    "#         print \"Recall-{}\".format(self.recall)\n",
    "        if self.precision == 0 and self.recall == 0:\n",
    "            self.f1 = 0\n",
    "        else:\n",
    "            self.f1 = float(2*self.precision*self.recall)/\\\n",
    "                    float(self.precision+self.recall)\n",
    "\n",
    "            \n",
    "        return\n",
    "            \n",
    "    def monitorMetrics(self, nIteration):\n",
    "        \n",
    "        Y = np.asarray([self.error.data[0]])\n",
    "        X = np.asarray([nIteration])\n",
    "        \n",
    "        if not self.win_err:\n",
    "            self.win_err = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='error plot',\\\n",
    "                                         markercolor=np.array([255])))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_err)\n",
    "        \n",
    "        Y = np.asarray([self.f1])\n",
    "        if not self.win_f1:\n",
    "            self.win_f1 = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='f1 plot'))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_f1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        dtype = torch.FloatTensor\n",
    "        targets = Variable(patterns[:,0].type(dtype), requires_grad=False)\n",
    "        inputs = Variable(patterns[:,1:].type(dtype))\n",
    "        \n",
    "        predictions = self.model(inputs)\n",
    "        predictions = (predictions >= 0.5).type(torch.FloatTensor)\n",
    "        \n",
    "        #print type(predictions)\n",
    "        #print type(targets)\n",
    "        for i,_ in enumerate(predictions):\n",
    "            \n",
    "            if predictions[i].data[0] == targets[i].data[0]:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    #print targets[i][0], predictions[i][0]\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if targets[i][0] == 1.0:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        \n",
    "        print \"tp, fp, tn, fn\"\n",
    "        print tp, fp, tn, fn\n",
    "        \n",
    "        try:\n",
    "            precision = float(tp)/float(tp + fp)\n",
    "        except:\n",
    "            precision = 0.0\n",
    "        try:\n",
    "            recall = float(tp)/float(tp + fn)\n",
    "        except:\n",
    "            recall = 0.0\n",
    "            \n",
    "        try:\n",
    "            fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        except:\n",
    "            fscore = 0.0\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n",
      "Begin training!!\n",
      "error 200.95276\n",
      "error 244.98769\n",
      "error 255.26541\n",
      "error 235.75806\n",
      "error 227.81648\n",
      "error 224.47012\n",
      "error 224.93889\n",
      "error 229.95857\n",
      "error 234.50011\n",
      "error 233.42291\n",
      "error 227.03203\n",
      "error 218.07259\n",
      "error 206.89297\n",
      "error 193.26768\n",
      "error 177.53993\n",
      "error 160.87122\n",
      "error 144.46809\n",
      "error 126.38390\n",
      "error 105.43635\n",
      "error 87.58039\n",
      "error 70.91177\n",
      "error 52.79420\n",
      "error 37.27246\n",
      "error 25.98798\n",
      "error 22.33052\n",
      "error 50.82478\n",
      "error 15.79206\n",
      "error 13.14632\n",
      "error 11.96210\n",
      "error 11.17510\n",
      "error 10.59436\n",
      "error 10.13479\n",
      "error 9.75497\n",
      "error 9.43135\n",
      "error 9.14752\n",
      "error 8.88880\n",
      "error 8.63905\n",
      "error 8.38181\n",
      "error 8.11819\n",
      "error 7.87926\n",
      "error 7.68283\n",
      "error 7.52185\n",
      "error 7.38617\n",
      "error 7.26858\n",
      "error 7.16438\n",
      "error 7.07021\n",
      "error 6.98332\n",
      "error 6.90068\n",
      "error 6.81702\n",
      "error 6.71549\n",
      "error 6.47138\n",
      "error 5.89732\n",
      "error 5.77202\n",
      "error 5.69599\n",
      "error 5.63503\n",
      "error 5.58213\n",
      "error 5.53460\n",
      "error 5.49110\n",
      "error 5.45084\n",
      "error 5.41331\n",
      "error 5.37812\n",
      "error 5.34501\n",
      "error 5.31374\n",
      "error 5.28415\n",
      "error 5.25606\n",
      "error 5.22936\n",
      "error 5.20393\n",
      "error 5.17966\n",
      "error 5.15646\n",
      "error 5.13426\n",
      "error 5.11298\n",
      "error 5.09255\n",
      "error 5.07291\n",
      "error 5.05401\n",
      "error 5.03579\n",
      "error 5.01821\n",
      "error 5.00121\n",
      "error 4.98476\n",
      "error 4.96881\n",
      "error 4.95334\n",
      "error 4.93831\n",
      "error 4.92366\n",
      "error 4.90940\n",
      "error 4.89547\n",
      "error 4.88187\n",
      "error 4.86855\n",
      "error 4.85550\n",
      "error 4.84270\n",
      "error 4.83012\n",
      "error 4.81776\n",
      "error 4.80558\n",
      "error 4.79359\n",
      "error 4.78177\n",
      "error 4.77010\n",
      "error 4.75858\n",
      "error 4.74722\n",
      "error 4.73598\n",
      "error 4.72488\n",
      "error 4.71392\n",
      "error 4.70310\n",
      "Total iterations- 1000\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "96 0 45 59\n",
      "Test done!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6193548387096774, 0.7649402390438247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test the NN by feeding in the X_train, X_test - output gives a \n",
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, True)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "dtype = torch.FloatTensor\n",
    "X_test = torch.Tensor(X[:int(0.2*ninputs)]).type(dtype)\n",
    "X_train = torch.Tensor(X[int(0.2*ninputs):]).type(dtype)\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "test_NN(nfeatures, X_train, X_test, iteration=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets change iterations and check the effect on fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training iteration- 50\n",
      "Begin training!!\n",
      "error 202.21870\n",
      "error 211.85374\n",
      "error 261.76532\n",
      "error 238.29131\n",
      "error 230.24199\n",
      "Total iterations- 50\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "0 0 88 112\n",
      "Test done!!\n",
      "Done with iteration -50\n",
      "Begin training iteration- 100\n",
      "Begin training!!\n",
      "error 200.49733\n",
      "error 208.12291\n",
      "error 263.36975\n",
      "error 242.37692\n",
      "error 232.28908\n",
      "error 229.61522\n",
      "error 231.19913\n",
      "error 231.20139\n",
      "error 222.94147\n",
      "error 206.55118\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "12 0 83 105\n",
      "Test done!!\n",
      "Done with iteration -100\n",
      "Begin training iteration- 200\n",
      "Begin training!!\n",
      "error 199.82240\n",
      "error 199.37163\n",
      "error 271.48053\n",
      "error 241.81291\n",
      "error 232.22414\n",
      "error 230.04262\n",
      "error 232.65671\n",
      "error 234.55408\n",
      "error 229.78964\n",
      "error 219.04262\n",
      "error 206.06609\n",
      "error 191.73019\n",
      "error 175.97552\n",
      "error 159.17747\n",
      "error 142.56853\n",
      "error 126.84791\n",
      "error 110.98123\n",
      "error 94.01676\n",
      "error 78.82909\n",
      "error 63.95086\n",
      "Total iterations- 200\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "52 0 71 77\n",
      "Test done!!\n",
      "Done with iteration -200\n",
      "Begin training iteration- 500\n",
      "Begin training!!\n",
      "error 201.20967\n",
      "error 311.89890\n",
      "error 262.83530\n",
      "error 239.07521\n",
      "error 230.84442\n",
      "error 228.97496\n",
      "error 231.09474\n",
      "error 231.62355\n",
      "error 223.83344\n",
      "error 208.31807\n",
      "error 189.93556\n",
      "error 171.25298\n",
      "error 151.96939\n",
      "error 133.18033\n",
      "error 117.93049\n",
      "error 106.35892\n",
      "error 96.23031\n",
      "error 84.43768\n",
      "error 70.70491\n",
      "error 60.08933\n",
      "error 48.82811\n",
      "error 34.22310\n",
      "error 29.62022\n",
      "error 171.99646\n",
      "error 20.16408\n",
      "error 15.29267\n",
      "error 12.45953\n",
      "error 10.82196\n",
      "error 9.87627\n",
      "error 9.24786\n",
      "error 8.78119\n",
      "error 8.40531\n",
      "error 8.08051\n",
      "error 7.77757\n",
      "error 7.47324\n",
      "error 7.16999\n",
      "error 6.90281\n",
      "error 6.68615\n",
      "error 6.51003\n",
      "error 6.36286\n",
      "error 6.23667\n",
      "error 6.12628\n",
      "error 6.02828\n",
      "error 5.94030\n",
      "error 5.86062\n",
      "error 5.78792\n",
      "error 5.72116\n",
      "error 5.65954\n",
      "error 5.60235\n",
      "error 5.54905\n",
      "Total iterations- 500\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "95 0 47 58\n",
      "Test done!!\n",
      "Done with iteration -500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e00dfc190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['100', '200', '500', '1000'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check whether neuron values affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training neuron- 5\n",
      "Begin training!!\n",
      "error 202.81497\n",
      "error 267.63199\n",
      "error 232.65976\n",
      "error 223.70927\n",
      "error 222.81496\n",
      "error 225.62512\n",
      "error 223.25516\n",
      "error 211.83685\n",
      "error 191.93623\n",
      "error 170.44685\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "28 0 81 91\n",
      "Test done!!\n",
      "Done with neuron -5\n",
      "Begin training neuron- 10\n",
      "Begin training!!\n",
      "error 200.54482\n",
      "error 336.16220\n",
      "error 241.04959\n",
      "error 229.76460\n",
      "error 224.24388\n",
      "error 220.99992\n",
      "error 218.02667\n",
      "error 212.99498\n",
      "error 206.88260\n",
      "error 199.88979\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "112 0 0 88\n",
      "Test done!!\n",
      "Done with neuron -10\n",
      "Begin training neuron- 20\n",
      "Begin training!!\n",
      "error 201.77432\n",
      "error 372.30136\n",
      "error 372.88092\n",
      "error 291.19577\n",
      "error 237.79047\n",
      "error 248.10295\n",
      "error 225.47803\n",
      "error 221.25693\n",
      "error 214.72400\n",
      "error 208.51321\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "112 0 0 88\n",
      "Test done!!\n",
      "Done with neuron -20\n",
      "Begin training neuron- 30\n",
      "Begin training!!\n",
      "error 210.11028\n",
      "error 375.97479\n",
      "error 207.65024\n",
      "error 228.77515\n",
      "error 387.27100\n",
      "error 383.48557\n",
      "error 231.00636\n",
      "error 404.78836\n",
      "error 217.20070\n",
      "error 300.02417\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "tp, fp, tn, fn\n",
      "112 0 0 88\n",
      "Test done!!\n",
      "Done with neuron -30\n"
     ]
    }
   ],
   "source": [
    "### Now test with different neuron values for iteration limit of 100\n",
    "neurons = [5, 10, 20, 30]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of iterations to be 100\n",
    "for neuron in neurons:\n",
    "    print \"Begin training neuron- {}\".format(neuron)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, 100, neuron, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with neuron -{}\".format(neuron)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4de6c70a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neurons = [10, 20, 30, 40]\n",
    "neurons = np.asarray(neurons)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(neurons-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(neurons, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(neurons+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(neurons, ['5', '10', '20', '30'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0|0|\n",
      "-------\n",
      "|0|0|\n",
      "-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'pane_350562370c7a28'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "vis = visdom.Visdom()\n",
    "cm = ConfusionMatrix()\n",
    "vis.text(cm.dispMatrix())\n",
    "vis.image(np.ones((3, 10, 10)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
