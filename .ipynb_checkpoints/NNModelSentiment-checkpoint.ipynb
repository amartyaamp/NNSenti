{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "##### Output -\n",
    "Model for predicting sentiment class\n",
    "##### Notes -\n",
    "I am using a feed forward 1 hidden layer net. Using only count vectors as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load the data from the file and create the input matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        \n",
    "        #skip punctuations\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[[ 0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "# Main function to form the input matrix\n",
    "#TODO - maybe form a loader class later\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "print data[:,0]\n",
    "print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN\n",
    "\n",
    "A feed forward net is formed using back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations = 50,\\\n",
    "                 learning_rate = 0.02):\n",
    "        \n",
    "        self.input = input + 1 # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # set up array of 1s for activations\n",
    "        self.ai = [1.0] * self.input\n",
    "        self.ah = [1.0] * self.hidden\n",
    "        self.ao = [1.0] * self.output\n",
    "        # create randomized weights\n",
    "        self.wi = np.random.randn(self.input, self.hidden) \n",
    "        self.wo = np.random.randn(self.hidden, self.output) \n",
    "        # create arrays of 0 for changes\n",
    "        #self.ci = np.zeros((self.input, self.hidden))\n",
    "        #self.co = np.zeros((self.hidden, self.output))\n",
    "\n",
    "        \n",
    "    def feedForward(self, inputs):\n",
    "       \n",
    "        assert(len(inputs) == self.input-1)\n",
    "        \n",
    "        # input activations\n",
    "        for i in range(self.input -1): # -1 is to avoid the bias\n",
    "            self.ai[i] = inputs[i]\n",
    "        # hidden activations\n",
    "        for j in range(self.hidden):\n",
    "            sum = 0.0\n",
    "            for i in range(self.input):\n",
    "                sum += self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "        # output activations\n",
    "        for k in range(self.output):\n",
    "            sum = 0.0\n",
    "            for j in range(self.hidden):\n",
    "                sum += self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "        return self.ao[:]\n",
    "    \n",
    "    \n",
    "    def backPropagate(self, targets, N):\n",
    "        \n",
    "        assert(len(targets) == self.output)\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        # the delta tell you which direction to change the weights\n",
    "        output_deltas = [0.0] * self.output\n",
    "        for k in range(self.output):\n",
    "            error = -(targets[k] - self.ao[k])\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "        \n",
    "        # calculate error terms for hidden\n",
    "        # delta tells you which direction to change the weights\n",
    "        hidden_deltas =  [0.0] * self.hidden\n",
    "        for j in range(self.hidden):\n",
    "            error = 0.0\n",
    "            for k in range(self.output):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "        \n",
    "        # update the weights hidden-output\n",
    "        for j in range(self.hidden):\n",
    "            for k in range(self.output):\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] -= N * change #+ self.co[j][k]\n",
    "                #self.co[j][k] = change\n",
    "        \n",
    "        # update the weights input-hidden\n",
    "        for i in range(self.input):\n",
    "            for j in range(self.hidden):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                self.wi[i][j] -= N * change #+ self.ci[i][j]\n",
    "                #self.ci[i][j] = change\n",
    "        \n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error += 0.5 * (targets[k] - self.ao[k]) ** 2\n",
    "        return error\n",
    "    \n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        # N: learning rate\n",
    "        itercount = 0\n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            error, prev_error = 0.0, 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[1:]\n",
    "                targets = p[0]\n",
    "                self.feedForward(inputs)\n",
    "                error = self.backPropagate([targets],\\\n",
    "                                           self.learning_rate)\n",
    "                        \n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for p in patterns:\n",
    "            pred = self.feedForward(p[1:])\n",
    "            res = 1 if pred[0] >= 0.5 else 0\n",
    "            if logs:\n",
    "                print \"{} -> {}\".format(p[0], res)\n",
    "            if p[0] == res:\n",
    "                if p[0] == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if p[0] == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        precision =  float(tp)/float(tp+fp)\n",
    "        recall = float(tp)/float(tp+fn)\n",
    "        fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        if logs:\n",
    "            print \"precision - {}\".format(precision)\n",
    "            print \"recall - {}\".format(recall)\n",
    "            print \"F1 score - {}\".format(fscore)\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "## test the NN by feeding in the X_train, X_test - output gives a \n",
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, False)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "\n",
    "X_test = X[:int(0.2*ninputs)]\n",
    "X_train = X[int(0.2*ninputs):]\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "#test_NN(nfeatures, X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training iteration- 50\n",
      "Begin training!!\n",
      "error 0.37151\n",
      "error 0.04308\n",
      "error 0.03913\n",
      "error 0.03786\n",
      "error 0.03588\n",
      "Total iterations- 50\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -50\n",
      "Begin training iteration- 100\n",
      "Begin training!!\n",
      "Total iterations- 0\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -100\n",
      "Begin training iteration- 200\n",
      "Begin training!!\n",
      "error 0.01497\n",
      "error 0.01571\n",
      "error 0.01592\n",
      "error 0.01473\n",
      "error 0.01285\n",
      "error 0.01080\n",
      "error 0.00883\n",
      "error 0.00707\n",
      "error 0.00556\n",
      "error 0.00429\n",
      "error 0.00327\n",
      "error 0.00246\n",
      "error 0.00183\n",
      "error 0.00135\n",
      "error 0.00099\n",
      "error 0.00072\n",
      "error 0.00052\n",
      "Total iterations- 170\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -200\n",
      "Begin training iteration- 500\n",
      "Begin training!!\n",
      "error 0.21165\n",
      "error 0.12792\n",
      "error 0.08130\n",
      "error 0.06822\n",
      "error 0.06276\n",
      "error 0.05896\n",
      "error 0.05534\n",
      "error 0.05157\n",
      "error 0.04763\n",
      "error 0.04361\n",
      "error 0.03957\n",
      "error 0.03560\n",
      "error 0.03176\n",
      "error 0.02811\n",
      "error 0.02469\n",
      "error 0.02154\n",
      "error 0.01869\n",
      "error 0.01615\n",
      "error 0.01392\n",
      "error 0.01196\n",
      "error 0.01027\n",
      "error 0.00882\n",
      "error 0.00758\n",
      "error 0.00653\n",
      "error 0.00565\n",
      "error 0.00490\n",
      "error 0.00428\n",
      "error 0.00375\n",
      "error 0.00330\n",
      "error 0.00291\n",
      "error 0.00258\n",
      "error 0.00231\n",
      "error 0.00208\n",
      "error 0.00191\n",
      "error 0.00177\n",
      "error 0.00166\n",
      "error 0.00158\n",
      "error 0.00152\n",
      "error 0.00146\n",
      "error 0.00140\n",
      "error 0.00132\n",
      "error 0.00122\n",
      "error 0.00110\n",
      "error 0.00099\n",
      "error 0.00087\n",
      "error 0.00077\n",
      "error 0.00067\n",
      "error 0.00058\n",
      "error 0.00051\n",
      "Total iterations- 490\n",
      "Done with training! Begin Tests!\n",
      "Test done!!\n",
      "Done with iteration -500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f588a444f7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;31m## Uncomment below to share the values for precision, recall etc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# print iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['50', '100', '200', '500'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Now test with different neural values for iteration limit of 100\n",
    "neurons = [5, 10, 20, 30]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
