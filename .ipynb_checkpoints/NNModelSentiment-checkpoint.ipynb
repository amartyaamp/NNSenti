{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "#### Output -\n",
    "Model for predicting sentiment class\n",
    "#### Notes -\n",
    "I am using a feed forward 1 hidden layer net. Using only count vectors as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load the data from the file and create the input matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        \n",
    "        #skip punctuations\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[[ 0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "# Main function to form the input matrix\n",
    "#TODO - maybe form a loader class later\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "print data[:,0]\n",
    "print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN\n",
    "\n",
    "A feed forward net is formed using back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, tp=0, tn=0, fp=0, fn=0):\n",
    "        \n",
    "        self.tp = tp\n",
    "        self.tn = tn\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def dispMatrix(self):\n",
    "        \n",
    "        s = \"|{}|{}|\".format(self.tp, self.fn)\n",
    "        s += \"\\n-------\"\n",
    "        s += \"\\n|{}|{}|\".format(self.fp, self.tn)\n",
    "        s += \"\\n-------\"\n",
    "        print s\n",
    "        return s\n",
    "    \n",
    "    def getPrecision(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fp);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    \n",
    "    def getRecall(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fn);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations = 50,\\\n",
    "                 learning_rate = 0.02):\n",
    "        \n",
    "        self.input = input + 1 # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # set up array of 1s for activations\n",
    "        self.ai = [1.0] * self.input\n",
    "        self.ah = [1.0] * self.hidden\n",
    "        self.ao = [1.0] * self.output\n",
    "        # create randomized weights\n",
    "        self.wi = np.random.randn(self.input, self.hidden) \n",
    "        self.wo = np.random.randn(self.hidden, self.output) \n",
    "        \n",
    "        # Metrics for the model\n",
    "        self.cmatrix = ConfusionMatrix()\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.f1 = 0.0\n",
    "        \n",
    "        #the graphics elements\n",
    "        self.vis = visdom.Visdom()\n",
    "        self.win_f1 = None\n",
    "        self.win_err = None\n",
    "        \n",
    "\n",
    "        \n",
    "    def feedForward(self, inputs):\n",
    "       \n",
    "        assert(len(inputs) == self.input-1)\n",
    "        \n",
    "        # input activations\n",
    "        for i in range(self.input -1): # -1 is to avoid the bias\n",
    "            self.ai[i] = inputs[i]\n",
    "        # hidden activations\n",
    "        for j in range(self.hidden):\n",
    "            sum = 0.0\n",
    "            for i in range(self.input):\n",
    "                sum += self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "        # output activations\n",
    "        for k in range(self.output):\n",
    "            sum = 0.0\n",
    "            for j in range(self.hidden):\n",
    "                sum += self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "        return self.ao[:]\n",
    "    \n",
    "    \n",
    "    def backPropagate(self, targets, N):\n",
    "        \n",
    "        assert(len(targets) == self.output)\n",
    "        \n",
    "        # calculate error terms for output\n",
    "        # the delta tell you which direction to change the weights\n",
    "        output_deltas = [0.0] * self.output\n",
    "        for k in range(self.output):\n",
    "            error = -(targets[k] - self.ao[k])\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "        \n",
    "        # calculate error terms for hidden\n",
    "        # delta tells you which direction to change the weights\n",
    "        hidden_deltas =  [0.0] * self.hidden\n",
    "        for j in range(self.hidden):\n",
    "            error = 0.0\n",
    "            for k in range(self.output):\n",
    "                error += output_deltas[k] * self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "        \n",
    "        # update the weights hidden-output\n",
    "        for j in range(self.hidden):\n",
    "            for k in range(self.output):\n",
    "                change = output_deltas[k] * self.ah[j]\n",
    "                self.wo[j][k] -= N * change\n",
    "                \n",
    "        \n",
    "        # update the weights input-hidden\n",
    "        for i in range(self.input):\n",
    "            for j in range(self.hidden):\n",
    "                change = hidden_deltas[j] * self.ai[i]\n",
    "                self.wi[i][j] -= N * change\n",
    "        \n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error += 0.5 * (targets[k] - self.ao[k]) ** 2\n",
    "        self.error = error\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        # N: learning rate\n",
    "        itercount = 0\n",
    "        error, prev_error = 0.0, 0.0\n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            \n",
    "            for p in patterns:\n",
    "                inputs = p[1:]\n",
    "                targets = p[0]\n",
    "                predicts = self.feedForward(inputs)[0]\n",
    "                \n",
    "                predicts = 0 if predicts < 0.5 else 1\n",
    "                if(predicts == targets):\n",
    "                    if targets == 1:\n",
    "                        self.cmatrix.tp += 1\n",
    "                    else:\n",
    "                        self.cmatrix.tn += 1\n",
    "                else:\n",
    "                    if targets == 1:\n",
    "                        self.cmatrix.fn += 1\n",
    "                    else:\n",
    "                        self.cmatrix.fp += 1\n",
    "                        \n",
    "                error = self.backPropagate([targets],\\\n",
    "                                           self.learning_rate)\n",
    "                self.error = error\n",
    "                self.updateMetrics()\n",
    "                        \n",
    "            self.monitorMetrics(itercount)\n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            \n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateMetrics(self):\n",
    "            \n",
    "        self.precision = self.cmatrix.getPrecision()\n",
    "#         print \"Precision-{}\".format(self.precision)\n",
    "        self.recall = self.cmatrix.getRecall()\n",
    "#         print \"Recall-{}\".format(self.recall)\n",
    "        if self.precision == 0 and self.recall == 0:\n",
    "            self.f1 = 0\n",
    "        else:\n",
    "            self.f1 = float(2*self.precision*self.recall)/\\\n",
    "                    float(self.precision+self.recall)\n",
    "\n",
    "            \n",
    "        return\n",
    "            \n",
    "    def monitorMetrics(self, nIteration):\n",
    "        \n",
    "        Y = np.asarray([self.error])\n",
    "        X = np.asarray([nIteration])\n",
    "        \n",
    "        if not self.win_err:\n",
    "            self.win_err = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='error plot',\\\n",
    "                                         markercolor=np.array([255])))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_err)\n",
    "        \n",
    "        Y = np.asarray([self.f1])\n",
    "        if not self.win_f1:\n",
    "            self.win_f1 = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='f1 plot'))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_f1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for p in patterns:\n",
    "            pred = self.feedForward(p[1:])\n",
    "            res = 1 if pred[0] >= 0.5 else 0\n",
    "            if logs:\n",
    "                print \"{} -> {}\".format(p[0], res)\n",
    "            if p[0] == res:\n",
    "                if p[0] == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if p[0] == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        precision =  float(tp)/float(tp+fp)\n",
    "        recall = float(tp)/float(tp+fn)\n",
    "        fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        if logs:\n",
    "            print \"precision - {}\".format(precision)\n",
    "            print \"recall - {}\".format(recall)\n",
    "            print \"F1 score - {}\".format(fscore)\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n",
      "Begin training!!\n"
     ]
    }
   ],
   "source": [
    "## test the NN by feeding in the X_train, X_test - output gives a \n",
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, False)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "\n",
    "X_test = X[:int(0.2*ninputs)]\n",
    "X_train = X[int(0.2*ninputs):]\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "test_NN(nfeatures, X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets change iterations and check the effect on fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['50', '100', '200', '500'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check whether neuron values affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now test with different neuron values for iteration limit of 100\n",
    "neurons = [5, 10, 20, 30]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of iterations to be 100\n",
    "for neuron in neurons:\n",
    "    print \"Begin training neuron- {}\".format(neuron)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, 100, neuron, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with neuron -{}\".format(neuron)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons = [10, 20, 30, 40]\n",
    "neurons = np.asarray(neurons)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(neurons-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(neurons, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(neurons+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(neurons, ['5', '10', '20', '30'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "vis = visdom.Visdom()\n",
    "cm = ConfusionMatrix()\n",
    "vis.text(cm.dispMatrix())\n",
    "vis.image(np.ones((3, 10, 10)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
