{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Data -\n",
    "Reviews and their labels (sentiments)\n",
    "#### Output -\n",
    "Model for predicting sentiment class\n",
    "#### Notes -\n",
    "I am using a feed forward 1 hidden layer net. Using only count vectors as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1 - Gathering the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to load the data from the file and create the input matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keeping it simple word count only as features.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_sent_word_count(sample_file):\n",
    "    file_as_lines =[]\n",
    "    sentiments = []\n",
    "    index = 0\n",
    "    word_count = {}\n",
    "\n",
    "    for line in sample_file:\n",
    "        line = line.strip()\n",
    "        sentiments.append(int(line[-1]))\n",
    "        line = line[:-1].strip()\n",
    "        \n",
    "        #skip punctuations\n",
    "        chars_to_avoid = '-:,;[({})]!?'\n",
    "        for word in line.split():\n",
    "            if word not in word_count:\n",
    "                word = word.lower()\n",
    "                #remove punctuations in word\n",
    "                for c in chars_to_avoid:\n",
    "                    word = word.replace(c, '')\n",
    "                word_count[word] = [(index, 1)]\n",
    "            else:\n",
    "                prev_index, count = word_count[word][-1]\n",
    "                if prev_index == index:\n",
    "                    count += 1\n",
    "                    word_count[word][-1] = (index, count)\n",
    "                else:\n",
    "                    count = 1\n",
    "                    word_count[word].append((index, count))\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    #print word_count, sentiments\n",
    "    \n",
    "    return sentiments, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[[ 0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "### Now forming the input vectors from word_count\n",
    "\n",
    "def get_wcm(word_count, ninputs):\n",
    "    ## feature_count - no of words\n",
    "    ## inputs - file count\n",
    "    features = word_count.keys()\n",
    "    # print features\n",
    "    nfeatures = len(features)\n",
    "    #ninputs = index\n",
    "    word_count_matrix = np.zeros((ninputs, nfeatures))\n",
    "\n",
    "    for wcm_col, feature in enumerate(features):\n",
    "        row_col_list = word_count[feature]\n",
    "    #     print row_col_list\n",
    "        for wcm_row, wcm_val in row_col_list:\n",
    "            word_count_matrix[wcm_row][wcm_col] = wcm_val\n",
    "    \n",
    "    return word_count_matrix\n",
    "\n",
    "# Main function to form the input matrix\n",
    "#TODO - maybe form a loader class later\n",
    "def load_data(filename):\n",
    "    sentiments, word_count = get_sent_word_count(filename)\n",
    "    #get word_count matrix\n",
    "    wcm = get_wcm(word_count, len(sentiments))\n",
    "    sentiments = np.asarray(sentiments)\n",
    "    data = wcm\n",
    "    data[:, 0] = sentiments\n",
    "    return data\n",
    "\n",
    "sample_file = open(\"sample.txt\", \"r\")\n",
    "data = load_data(sample_file)\n",
    "sample_file.close()\n",
    "print data[:,0]\n",
    "print data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task2 - Forming the NN\n",
    "\n",
    "A feed forward net is formed using back-propagation. Here we change as to use of torch.nn framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the below sigmoid funcs are not needed keeping them redundantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a  Feed forward NN model\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1.0 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix as a performance evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    \n",
    "    def __init__(self, tp=0, tn=0, fp=0, fn=0):\n",
    "        \n",
    "        self.tp = tp\n",
    "        self.tn = tn\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def dispMatrix(self):\n",
    "        \n",
    "        s = \"|{}|{}|\".format(self.tp, self.fn)\n",
    "        s += \"\\n-------\"\n",
    "        s += \"\\n|{}|{}|\".format(self.fp, self.tn)\n",
    "        s += \"\\n-------\"\n",
    "        print s\n",
    "        return s\n",
    "    \n",
    "    def getPrecision(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fp);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    \n",
    "    def getRecall(self):\n",
    "        \n",
    "        try:\n",
    "            return float(self.tp)/float(self.tp + self.fn);\n",
    "        except:\n",
    "#             print \"Division error!!\"\n",
    "            return 0\n",
    "        \n",
    "        assert(False)\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "class MLP_NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input, hidden, output, iterations=50,\\\n",
    "                 learning_rate = 0.02, batchsize=100):\n",
    "        \n",
    "        # all the parameters' count\n",
    "        self.input = input # add 1 for bias node\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batchsize = batchsize\n",
    "        \n",
    "        ## Since it is torch.NN, we need inputs and output \n",
    "        ## tensors instead of weights\n",
    "        self.model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(self.input, self.hidden),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(self.hidden, self.output),\n",
    "          torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "        \n",
    "        # Metrics for the model\n",
    "        self.cmatrix = ConfusionMatrix()\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.f1 = 0.0\n",
    "        \n",
    "        #the graphics elements\n",
    "        self.vis = visdom.Visdom()\n",
    "        self.win_f1 = None\n",
    "        self.win_err = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    ##Now we go for train and predict\n",
    "    def train(self, patterns, logs=False):\n",
    "        \n",
    "        dtype = torch.FloatTensor\n",
    "        itercount = 0\n",
    "        error, prev_error = 0.0, 0.0\n",
    "        \n",
    "        #type casting required to make all of them float Tensor\n",
    "        targets = Variable(patterns[:,0].type(dtype), requires_grad=False)\n",
    "        inputs = Variable(patterns[:,1:].type(dtype))\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            if logs:\n",
    "                print \"Iteration - {}\".format(i)\n",
    "            \n",
    "            ##feed forward\n",
    "            predictions = self.model(inputs)\n",
    "            self.error = self.loss_fn(predictions, targets)\n",
    "            \n",
    "            error = self.error.data[0]\n",
    "            \n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            self.error.backward() # do backpropagation now\n",
    "            \n",
    "            for param in self.model.parameters():\n",
    "                param.data -= self.learning_rate * param.grad.data\n",
    "            \n",
    "            #quantize the predictions to 0 or 1\n",
    "            predictions = (predictions >= 0.5).type(dtype)\n",
    "            \n",
    "            ## TODO - uncomment to set the confusion matrix stats\n",
    "            self.updateMetrics(targets, predictions)\n",
    "            \n",
    "            # Get the vizdom plot\n",
    "            self.monitorMetrics(itercount)\n",
    "            \n",
    "            ## print the error at every 10th iteration\n",
    "            ## also stop if the error value is too less or its not converging\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                delta = abs(error - prev_error)\n",
    "                if delta < 0.000005 or error <= 0.0005:\n",
    "                    print \"breaking the game\"\n",
    "                    break\n",
    "                prev_error = error\n",
    "                print('error %-.5f' % error)\n",
    "            \n",
    "            itercount += 1\n",
    "        \n",
    "        print \"Total iterations- {}\".format(itercount)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateMetrics(self, targets, predictions):\n",
    "        \n",
    "        for i,_ in enumerate(predictions):\n",
    "            if predictions[i].data[0] == targets[i].data[0]:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    self.cmatrix.tp += 1\n",
    "                else:\n",
    "                    self.cmatrix.tn += 1\n",
    "            else:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    self.cmatrix.fn += 1\n",
    "                else:\n",
    "                    self.cmatrix.fp += 1\n",
    "        \n",
    "        self.precision = self.cmatrix.getPrecision()\n",
    "#         print \"Precision-{}\".format(self.precision)\n",
    "        self.recall = self.cmatrix.getRecall()\n",
    "#         print \"Recall-{}\".format(self.recall)\n",
    "        if self.precision == 0 and self.recall == 0:\n",
    "            self.f1 = 0\n",
    "        else:\n",
    "            self.f1 = float(2*self.precision*self.recall)/\\\n",
    "                    float(self.precision+self.recall)\n",
    "\n",
    "            \n",
    "        return\n",
    "            \n",
    "    def monitorMetrics(self, nIteration):\n",
    "        \n",
    "        Y = np.asarray([self.error.data[0]])\n",
    "        X = np.asarray([nIteration])\n",
    "        \n",
    "        if not self.win_err:\n",
    "            self.win_err = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='error plot',\\\n",
    "                                         markercolor=np.array([255])))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_err)\n",
    "        \n",
    "        Y = np.asarray([self.f1])\n",
    "        if not self.win_f1:\n",
    "            self.win_f1 = self.vis.line(Y,X, opts=\\\n",
    "                                     dict(title='f1 plot'))\n",
    "        else:       \n",
    "            self.vis.updateTrace(X, Y, win=self.win_f1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    ## Just to get some output and calc precision/recall\n",
    "    def test(self, patterns, logs=False):\n",
    "        ## target val vs predicted val\n",
    "        tot = len(patterns)\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        dtype = torch.FloatTensor\n",
    "        targets = Variable(patterns[:,0].type(dtype), requires_grad=False)\n",
    "        inputs = Variable(patterns[:,1:].type(dtype))\n",
    "        \n",
    "        predictions = self.model(inputs)\n",
    "        predictions = (predictions >= 0.5).type(torch.FloatTensor)\n",
    "        \n",
    "        print type(predictions)\n",
    "        print type(targets)\n",
    "        for i,_ in enumerate(predictions):\n",
    "            \n",
    "            if predictions[i].data[0] == targets[i].data[0]:\n",
    "                if targets[i].data[0] == 1.0:\n",
    "                    #print targets[i][0], predictions[i][0]\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if targets[i][0] == 1.0:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        print tp, fp, tn, fn\n",
    "        try:\n",
    "            precision = float(tp)/float(tp + fp)\n",
    "        except:\n",
    "            precision = 0.0\n",
    "        try:\n",
    "            recall = float(tp)/float(tp + fn)\n",
    "        except:\n",
    "            recall = 0.0\n",
    "            \n",
    "        try:\n",
    "            fscore = float(2*precision*recall)/float(precision+recall)\n",
    "        except:\n",
    "            fscore = 0.0\n",
    "        \n",
    "        return (precision, recall, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!!\n",
      "2424\n",
      "1000\n",
      "Begin training!!\n",
      "error 200.07446\n",
      "error 330.54657\n",
      "error 248.39296\n",
      "error 231.36859\n",
      "error 225.36885\n",
      "error 221.25104\n",
      "error 215.58731\n",
      "error 207.16368\n",
      "error 198.19832\n",
      "error 189.08203\n",
      "error 180.80489\n",
      "error 173.03627\n",
      "error 164.09909\n",
      "error 152.53653\n",
      "error 139.80687\n",
      "error 125.43474\n",
      "error 107.90302\n",
      "error 88.96374\n",
      "error 72.45778\n",
      "error 57.72173\n",
      "error 39.96133\n",
      "error 30.73827\n",
      "error 135.40086\n",
      "error 24.71798\n",
      "error 16.56353\n",
      "error 13.65855\n",
      "error 12.01118\n",
      "error 10.94765\n",
      "error 9.97750\n",
      "error 9.19615\n",
      "error 8.73440\n",
      "error 8.37490\n",
      "error 8.06121\n",
      "error 7.76559\n",
      "error 7.46767\n",
      "error 7.17078\n",
      "error 6.90768\n",
      "error 6.69282\n",
      "error 6.51725\n",
      "error 6.36983\n",
      "error 6.24279\n",
      "error 6.13112\n",
      "error 6.03157\n",
      "error 5.94186\n",
      "error 5.86036\n",
      "error 5.78580\n",
      "error 5.71718\n",
      "error 5.65372\n",
      "error 5.59475\n",
      "error 5.53975\n",
      "error 5.48827\n",
      "error 5.43993\n",
      "error 5.39442\n",
      "error 5.35146\n",
      "error 5.31084\n",
      "error 5.27233\n",
      "error 5.23577\n",
      "error 5.20100\n",
      "error 5.16789\n",
      "error 5.13631\n",
      "error 5.10615\n",
      "error 5.07730\n",
      "error 5.04968\n",
      "error 5.02321\n",
      "error 4.99781\n",
      "error 4.97340\n",
      "error 4.94994\n",
      "error 4.92736\n",
      "error 4.90560\n",
      "error 4.88463\n",
      "error 4.86438\n",
      "error 4.84483\n",
      "error 4.82593\n",
      "error 4.80764\n",
      "error 4.78993\n",
      "error 4.77277\n",
      "error 4.75613\n",
      "error 4.74000\n",
      "error 4.72432\n",
      "error 4.70910\n",
      "error 4.69429\n",
      "error 4.67989\n",
      "error 4.66588\n",
      "error 4.65222\n",
      "error 4.63893\n",
      "error 4.62596\n",
      "error 4.61332\n",
      "error 4.60097\n",
      "error 4.58893\n",
      "error 4.57716\n",
      "error 4.56566\n",
      "error 4.55442\n",
      "error 4.54343\n",
      "error 4.53268\n",
      "error 4.52216\n",
      "error 4.51186\n",
      "error 4.50178\n",
      "error 4.49189\n",
      "error 4.48221\n",
      "error 4.47273\n",
      "Total iterations- 1000\n",
      "Done with training! Begin Tests!\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "95 0 46 59\n",
      "Test done!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6168831168831169, 0.7630522088353413)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test the NN by feeding in the X_train, X_test - output gives a \n",
    "def test_NN(nfeatures, X_train, X_test, iteration=50, neurons=10, learning_rate=0.02):\n",
    "    # Actual feautres is 1 less\n",
    "    NN = MLP_NeuralNetwork(nfeatures-1, neurons, 1, iteration, learning_rate)\n",
    "    print \"Begin training!!\"\n",
    "    NN.train(X_train, False)\n",
    "    print \"Done with training! Begin Tests!\"\n",
    "    p, r, f = NN.test(X_test, True)\n",
    "    print \"Test done!!\"\n",
    "    \n",
    "    return p, r, f\n",
    "\n",
    "\n",
    "##Now we test the above NN\n",
    "## Load the data\n",
    "sample_file = open(\"yelp_labelled.txt\", \"r\")\n",
    "X = load_data(sample_file)\n",
    "print \"data loaded!!\"\n",
    "sample_file.close()\n",
    "\n",
    "ninputs, nfeatures = X.shape\n",
    "print nfeatures\n",
    "print ninputs\n",
    "dtype = torch.FloatTensor\n",
    "X_test = torch.Tensor(X[:int(0.2*ninputs)]).type(dtype)\n",
    "X_train = torch.Tensor(X[int(0.2*ninputs):]).type(dtype)\n",
    "\n",
    "##Uncomment below to have an individual test\n",
    "test_NN(nfeatures, X_train, X_test, iteration=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3 - Lets make a plots of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets change iterations and check the effect on fscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training iteration- 50\n",
      "Begin training!!\n",
      "error 199.88109\n",
      "error 334.63300\n",
      "error 229.73608\n",
      "error 229.98268\n",
      "error 224.26241\n",
      "Total iterations- 50\n",
      "Done with training! Begin Tests!\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "112 0 0 88\n",
      "Test done!!\n",
      "Done with iteration -50\n",
      "Begin training iteration- 100\n",
      "Begin training!!\n",
      "error 209.91898\n",
      "error 208.09380\n",
      "error 262.69476\n",
      "error 242.52682\n",
      "error 232.38742\n",
      "error 229.77065\n",
      "error 230.50323\n",
      "error 227.50735\n",
      "error 215.89743\n",
      "error 196.06964\n",
      "Total iterations- 100\n",
      "Done with training! Begin Tests!\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "16 0 82 102\n",
      "Test done!!\n",
      "Done with iteration -100\n",
      "Begin training iteration- 200\n",
      "Begin training!!\n",
      "error 209.11398\n",
      "error 329.80991\n",
      "error 250.95233\n",
      "error 229.97917\n",
      "error 224.41306\n",
      "error 221.01851\n",
      "error 218.01567\n",
      "error 213.94740\n",
      "error 210.21889\n",
      "error 204.68433\n",
      "error 196.79863\n",
      "error 188.47838\n",
      "error 179.06111\n",
      "error 167.31488\n",
      "error 154.37782\n",
      "error 141.13083\n",
      "error 126.39921\n",
      "error 107.74647\n",
      "error 86.39388\n",
      "error 69.74317\n",
      "Total iterations- 200\n",
      "Done with training! Begin Tests!\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "105 0 24 71\n",
      "Test done!!\n",
      "Done with iteration -200\n",
      "Begin training iteration- 500\n",
      "Begin training!!\n",
      "error 200.83908\n",
      "error 235.57755\n",
      "error 259.59763\n",
      "error 238.18993\n",
      "error 230.08080\n",
      "error 227.85707\n",
      "error 229.73610\n",
      "error 231.95799\n",
      "error 227.39558\n",
      "error 214.42728\n",
      "error 197.43437\n",
      "error 179.47498\n",
      "error 160.85265\n",
      "error 141.89987\n",
      "error 125.40508\n",
      "error 112.49060\n",
      "error 101.63638\n",
      "error 89.89827\n",
      "error 76.28436\n",
      "error 64.03201\n",
      "error 52.72542\n",
      "error 38.40058\n",
      "error 28.23550\n",
      "error 37.86485\n",
      "error 96.80505\n",
      "error 17.54787\n",
      "error 13.99825\n",
      "error 11.77893\n",
      "error 10.35149\n",
      "error 9.54508\n",
      "error 8.99535\n",
      "error 8.57269\n",
      "error 8.21852\n",
      "error 7.89570\n",
      "error 7.57656\n",
      "error 7.25978\n",
      "error 6.97978\n",
      "error 6.75312\n",
      "error 6.56998\n",
      "error 6.41803\n",
      "error 6.28863\n",
      "error 6.17620\n",
      "error 6.07706\n",
      "error 5.98869\n",
      "error 5.90924\n",
      "error 5.83733\n",
      "error 5.77182\n",
      "error 5.71184\n",
      "error 5.65665\n",
      "error 5.60563\n",
      "Total iterations- 500\n",
      "Done with training! Begin Tests!\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "95 0 46 59\n",
      "Test done!!\n",
      "Done with iteration -500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# How does changing training iterations affect?\n",
    "   \n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of neurons to be 10\n",
    "for iteration in iterations:\n",
    "    print \"Begin training iteration- {}\".format(iteration)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, iteration, 10, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with iteration -{}\".format(iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = [10, 20, 30, 40]\n",
    "iterations = np.asarray(iterations)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(iterations-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(iterations, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(iterations+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(iterations, ['50', '100', '200', '500'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check whether neuron values affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Now test with different neuron values for iteration limit of 100\n",
    "neurons = [5, 10, 20, 30]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "fscores = []\n",
    "\n",
    "#keep number of iterations to be 100\n",
    "for neuron in neurons:\n",
    "    print \"Begin training neuron- {}\".format(neuron)\n",
    "    prec, rec, fscr = test_NN(nfeatures, X_train, X_test, 100, neuron, 0.02)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    fscores.append(fscr)\n",
    "    print \"Done with neuron -{}\".format(neuron)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons = [10, 20, 30, 40]\n",
    "neurons = np.asarray(neurons)\n",
    "## Uncomment below to share the values for precision, recall etc\n",
    "# print iterations\n",
    "# print recalls\n",
    "# print precisions\n",
    "# print fscores\n",
    "plt.bar(neurons-1, np.asarray(precisions),width=2, color='b',align='center', label='precision')\n",
    "plt.bar(neurons, np.asarray(recalls), width=2, color='g',align='center', label='recall')\n",
    "plt.bar(neurons+1, np.asarray(fscores), width=2,color='r',align='center', label='fscore')\n",
    "plt.xticks(neurons, ['5', '10', '20', '30'])\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Computing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "vis = visdom.Visdom()\n",
    "cm = ConfusionMatrix()\n",
    "vis.text(cm.dispMatrix())\n",
    "vis.image(np.ones((3, 10, 10)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Feed forward network driven sentiment analyser"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
